{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Fixed dimension MCMC with Eryn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张铭昊 北京化工大学 zmh780674484@163.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "教程3：基于Eryn的固定维度马尔可夫链蒙特卡洛（MCMC）方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from lisatools.utils.constants import *\n",
    "from copy import deepcopy  # can be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the third tutorial, we are going to learn how to use MCMC through `Eryn` to do our data analysis investigations. In this tutorial, we will stick with simple examples and simple signals (like in Tutorial 1). In later tutorials, we will use eryn with real GW signals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  在第三个教程中，我们将学习如何通过Eryn使用MCMC方法来进行数据分析。在这个教程中，我们将牢牢依据简单的例子和信号（像1那样）。在接下来的教程，\n",
    "我们将用Eryn处理真实的引力波信号。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: build your own basic MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "任务1：建立属于你自己的基本MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better understand MCMC and `Eryn`, we are going to start by building our own MCMC algorithm for a simple problem. We will do this with a single-dimensional Gaussian likelihood centered on ($\\mu=0$) and a unit standard deviation ($\\sigma=1$) and a uniform prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  为了更好地理解MCMC和Eryn，我们将从建立自己的关于一个简单问题的MCMC算法开始。我们将通过一个以(μ=0）为中心、有着单位标准差\n",
    "（σ=1）以及均匀先验性质的单维度高斯似然模型来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_gauss(x):\n",
    "    return -0.5 * x ** 2 - 1/2 * np.log(2 * np.pi * 1.0) # 1.0 is sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.linspace(-10.0, 10.0, 1000)\n",
    "# notice the `exp` in there because we are working with the log of the likelihood.\n",
    "plt.plot(x_vals, np.exp(log_like_gauss(x_vals)))\n",
    "plt.axvline(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are just going to write this into a simple loop. Gather your samples into the chain list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  我们仅仅需要把这些写入一个简单的循环语句。把你的样本集中到这个链表里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 100000\n",
    "\n",
    "# get random starting point\n",
    "current_point = np.random.uniform(-10.0, 10.0)\n",
    "current_likelihood = log_like_gauss(current_point)\n",
    "chain = []\n",
    "for step in range(num_steps):\n",
    "    # propose new point using a Gaussian distribution with standard deviation of 0.5\n",
    "    # hint: use current + sigma * N() where N() is a draw from a normal distribution \n",
    "    # (np.random.randn)\n",
    "\n",
    "    \n",
    "    # get new likelihood\n",
    "\n",
    "    \n",
    "    # calculate the change in posterior\n",
    "    # here we are using a uniform prior, so its value will not change, so for now do not\n",
    "    # worry about the prior.\n",
    "    \n",
    "    \n",
    "    # accept or reject\n",
    "    # if change in log posterior is greater than log(np.random.rand()), accept, else reject\n",
    "    \n",
    "    \n",
    "    if accept:\n",
    "        # update info if accepted\n",
    "\n",
    "    # append point to chain\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the chain. You will notice that the beginnning requires a \"burn in\" phase. So, when calculating the posterior, you must remove this. There are ways to calculate how much burn in is appropriate, but we will not get into that here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  现在请绘制这个链条。你将注意到开始阶段需要一个“燃烧”步骤。所以，当计算后验分布时，你需要移除掉这个阶段，这里有一些方法来计算“烧毁”多少数\n",
    "据是合理的，但我们不会在此深入讨论。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the posterior distribution generated by the MCMC and compare it against the true Likelihood plot from above. Remember to set `density=True` when building the histogram.\n",
    "\n",
    "If we take a step back here, we realize MCMC is really just a way to draw samples from a distribution. When the distribution is simple like this example, it will usually be available already with no need to run MCMC (like in scipy). However, in our area of work, the Likelihood distribution tends to be very difficult to deal with, which is why MCMC is so useful for us. To illustrate this, we will draw samples from the same distribution available in Numpy (`np.random.randn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  绘制MCMC生成的似然值后验分布并用它与上面绘制过的真实似然值比较。记得当建立直方图时要设置density=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_vals, np.exp(log_like_gauss(x_vals)))\n",
    "plt.hist(np.random.randn(100000), bins=40, density=True, histtype=\"step\")\n",
    "plt.hist(chain[10000:], bins=40, density=True, histtype=\"step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Use Eryn to reproduce the above result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `EnsembleSampler` in `Eryn` to reproduce the above results. If you are struggling, look at the `Eryn` tutorial. For Eryn, you will need to define a prior. Use `uniform_dist` to create a simple uniform distribution. For this example, you only need to worry about the Ensemble Sampler keyword arguments. Leave those all as default values and only enter the arguments.\n",
    "\n",
    "Useful documentation:\n",
    "* [EnsembleSampler](https://mikekatz04.github.io/Eryn/html/user/ensemble.html#eryn.ensemble.EnsembleSampler)\n",
    "* [State](https://mikekatz04.github.io/Eryn/html/user/state.html#eryn.state.State)\n",
    "* [uniform_dist](https://mikekatz04.github.io/Eryn/html/user/prior.html#eryn.prior.uniform_dist)\n",
    "* [ProbDistContainer](https://mikekatz04.github.io/Eryn/html/user/prior.html#eryn.prior.ProbDistContainer)\n",
    "* [Backend](https://mikekatz04.github.io/Eryn/html/user/backend.html#eryn.backends.Backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "任务2：使用Eryn来复现上述结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  现在请使用Eryn中的EnsembleSampler来复现上述结果。如果你在犹豫，看看Eryn教程。对于Eryn,你将需要定义一个先验的模型，使用uniform_dist来\n",
    "建立一个简单的均匀先验分布。对于这个例子，你只需要注意Ensemble Sampler这一关键字。让其他值都保持默认值然后仅仅输入这个关键字就行了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from eryn.ensemble import EnsembleSampler\n",
    "from eryn.state import State\n",
    "from eryn.prior import uniform_dist, ProbDistContainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize your sampler here. The prior initialization should take the form: `ProbDistContainer({0: prior distribution})`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "初始化你的样本。先验初始化需要采取这种形式：ProbDistContainer({0: prior distribution})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = ProbDistContainer({\n",
    "    0: uniform_dist(-1000.0, 1000.0)\n",
    "})\n",
    "nwalkers = 20\n",
    "ndim = 1 \n",
    "sampler = EnsembleSampler(nwalkers, 1, log_like_gauss, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now choose your starting point (one for each walker). You can draw from the prior or not. Just make sure to remove any burn in at the end. Then put the starting point into a `State` object. The key here is the start point should have shape `(1, nwalkers, 1, ndim)`. Here the two 1s are for temperatures (which we are not using right now) and the number of leaves or model count (this is for RJ). After this is complete, run the sampler.\n",
    "\n",
    "Documentation:\n",
    "* [run_mcmc](https://mikekatz04.github.io/Eryn/html/user/ensemble.html#eryn.ensemble.EnsembleSampler.run_mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  现在选择你的起点（给每一个游走状态）。你可以从先验分布中随机抽取起始点，也可以选择其他方法。无论选择哪种方式，请确保在最后移除任何“烧毁”\n",
    "阶段的样本。将起点放入State对象：将选定的起始点放入一个State对象中。在这里，关键点是起始点的形状应为(1, nwalkers, 1, ndim)。这里的两个\n",
    "1分别是用于温度（目前未使用）和叶子或模型数量（用于RJ，Reversible Jump）。在这完成之后，运行采样器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_point = prior.rvs(size=(1, nwalkers, 1))\n",
    "start_state = State(start_point)\n",
    "end_point = sampler.run_mcmc(start_state, 10000, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the output chains by using the backend:\n",
    "\n",
    "* [Backend](https://mikekatz04.github.io/Eryn/html/user/backend.html#eryn.backends.Backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  通过使用backend检查输出链:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = sampler.get_chain()[\"model_0\"]\n",
    "for w in range(nwalkers):\n",
    "    plt.plot(chain[:, 0, w, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare your output chains to the injected Gaussian distribution. They should match. Make sure when you plot the histogram, you set `density=True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  比较你的输出链和输入的高斯分布。它们应该相匹配。确保当你绘制出该直方图时，你设置了density=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(chain[1000:].flatten(), bins=40, density=True)\n",
    "plt.plot(x_vals, np.exp(log_like_gauss(x_vals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Parallel Tempering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add parallel tempering. In order to examine the effect of addering tempering, we are going to look at a 1D distribution with two Gaussian peaks with different weights. We have provided the log Likelihood function for this exercise. You just set the x limits to proper normalize the distribution.\n",
    "\n",
    "Parallel tempering works by supressing the Log Likelihood in comparison to the log prior: `1/T * logL + logp`. This effect lowers the peaks making it easier for higher temperature chains to traverse a low-Likelihood portion of the Likelihood surface. This helps to properly sample distributions with multiple posterior modes. \n",
    "\n",
    "We will start by sampling without tempering to see how well that does. Then we will add tempering to see the improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "任务3：并行淬火（Parallel Tempering）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  现在我们加入并行淬火。为了检查加入淬火的效果，我们将检查一个有着两个不同权重高斯峰的一维分布。我们已经提供了log Likelihood函数在练习中，\n",
    "你只需要设置对x的限制来对分布进行规范化。\n",
    "  并行淬火依据抑制对数似然值与对数先验函数1/T * logL + logp的相对影响的原理工作。这一效果降低了峰值，使高温链容易穿越似然值空间上的低似然\n",
    "值区域。这有助于恰当地抽取采样具有多个后验模态的分布。\n",
    "  我们将先在没有淬火的条件下看看运行的结果。然后我们加入淬火来看看有何改进。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "class LogLikeTwoGuass:\n",
    "    def __init__(self, x_min: float, x_max: float):\n",
    "        num_for_norm = 100000\n",
    "        self.norm = 1.0\n",
    "        x_vals = np.linspace(x_min, x_max, num_for_norm)\n",
    "        y_vals = np.array([np.exp(self.log_like_two_gauss(x_tmp)) for x_tmp in x_vals])\n",
    "        self.norm = np.trapz(y_vals, x=x_vals)\n",
    "        \n",
    "    def log_like_two_gauss(self, x):\n",
    "        return logsumexp(np.array([(np.log(0.2) + -0.5 * (x - 50.0) ** 2), (np.log(0.8) + -0.5 * (x + 50.0) ** 2)]), axis=0) - np.log(self.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like = LogLikeTwoGuass(-1000.0, 1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-491fa1293e60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m100.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# notice the `exp` in there because we are working with the log of the likelihood.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_like_two_gauss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#plt.plot(x_vals, np.exp(np.array([like.log_like_two_gauss(x_tmp) for x_tmp in x_vals])))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "x_vals = np.linspace(-100.0, 100.0, 1000)\n",
    "# notice the `exp` in there because we are working with the log of the likelihood.\n",
    "plt.plot(x_vals, np.exp(like.log_like_two_gauss(x_vals)))\n",
    "#plt.plot(x_vals, np.exp(np.array([like.log_like_two_gauss(x_tmp) for x_tmp in x_vals])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a non-tempered sampler. Run it and plot the histogram over the injected Likelihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  以一个无淬火的取样器作为开始状态。运行它并画出关于输入似然值的直方图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = ProbDistContainer({\n",
    "    0: uniform_dist(-1000.0, 1000.0)\n",
    "})\n",
    "nwalkers = 20\n",
    "ndim = 1 \n",
    "sampler = EnsembleSampler(nwalkers, 1, like.log_like_two_gauss, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "The plot should not look correct. Why do you think this is? When not using tempering, what determines the number of walkers inhabiting each peak?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-3-075ce56cedd8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-075ce56cedd8>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    绘制的图象看起来不对。你想一下这是为什么？当没有进行淬火时，什么决定了处于每一个峰值上的游走状态的数目？\u001b[0m\n\u001b[1;37m                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "  绘制的图象看起来不对。你想一下这是为什么？当没有进行淬火时，什么决定了处于每一个峰值上的游走状态的数目？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add temperatures by providing `tempering_kwargs` kwarg to `EnsembleSampler.\n",
    "\n",
    "Useful Documentation:\n",
    "* [EnsembleSampler](https://mikekatz04.github.io/Eryn/html/user/ensemble.html#eryn.ensemble.EnsembleSampler)\n",
    "* [TemperatureControl](https://mikekatz04.github.io/Eryn/html/user/temper.html#eryn.moves.tempering.TemperatureControl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntemps = 10\n",
    "sampler_pt = EnsembleSampler(nwalkers, 1, like.log_like_two_gauss, prior, tempering_kwargs=dict(ntemps=ntemps, Tmax=np.inf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample start points again from the prior with shape `(ntemps, nwalkers, 1, ndim)`. Then run the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  对起点再次进行采样，从先验模型中，使用形状 (ntemps, nwalkers, 1, ndim)。然后运行采样器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_point = prior.rvs(size=(ntemps, nwalkers, 1))\n",
    "start_state = State(start_point)\n",
    "sampler_pt.run_mcmc(start_state, 10000, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the plots should match very weel. Can you describe the change that took place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  现在图象应该与输入相匹配。你能描述发生了什么变化吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Add GWs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add GW signals in the form of the simple Sinusoid we used in the first tutorial. We will start with the waveform function. Set up the `DataResidualArray` (inject whatever parameter you would like), `SensitivityMatrix`, and `AnalysisContainer`. Remember, we do not have a response on this signal, so the sensitivity curve should be `LISASens`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "任务6:添加引力波！\n",
    "    现在我们将在第一个教程中使用的正弦信号形式下加入引力波信号。我们将从波形函数开始。设定DataResidualArray（输入你希望的一切参数），SensitivityMat\n",
    "rix以及 AnalysisContainer。记住，我们没有这个信号的响应，所以灵敏度曲线应该为LISASens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lisatools.datacontainer import DataResidualArray\n",
    "from lisatools.analysiscontainer import AnalysisContainer\n",
    "from lisatools.sensitivity import SensitivityMatrix, LISASens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add the waveform for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  我们将为你添加引力波。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_waveform(A: float, f0: float, phi0: float, t: np.ndarray, **kwargs) -> [np.ndarray, np.ndarray]:\n",
    "    h1 = A * np.sin(2 * np.pi * (f0 * t) + phi0)\n",
    "    h2 = A * np.cos(2 * np.pi * (f0 * t) + phi0)\n",
    "    return [h1, h2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the injection data, input it into a `DataResidualArray`, load a `SensitivityMatrix`, and store everything in an `AnalysisContainer`, including the sinusoidal waveform generator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  生成输入数据，将其输入一个DataResidualArray残差列数组，加载SensitivityMatrix，并要在AnalysisContainer存储所有内容，\n",
    "包含正弦波形发生器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 10.0\n",
    "t_arr = np.arange(100000) * dt\n",
    "data = DataResidualArray(sinusoidal_waveform(1e-21, 2e-3, np.pi / 3, t_arr), dt=dt)\n",
    "sens_mat = SensitivityMatrix(data.f_arr, [LISASens, LISASens])\n",
    "analysis = AnalysisContainer(data, sens_mat, signal_gen=sinusoidal_waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the SNR of the injection. (`AnalysisContainer.calculate_signal_snr`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "计算输入数据的信噪比，用(AnalysisContainer.calculate_signal_snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.calculate_signal_snr(1e-21, 2e-3, 0.0, t_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biuld the prior distributions for the three parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "建立三参数先验分布模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = ProbDistContainer({\n",
    "    0: uniform_dist(9e-22, 3e-21),\n",
    "    1: uniform_dist(1.5e-3, 2.5e-3),\n",
    "    2: uniform_dist(0.0, 2 * np.pi)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the sampler. For the Likelihood function, you can use `AnalysisContainer.eryn_likelihood_function`. For  now, we will not use tempering. This generation scheme is not efficient in terms of the Likelihood evaluation time. So, we will just run this as a quick example. You can run it longer later on and/or parallelize it with Eryn's `pool` capabilities. This basic example we are using illustrates the need for fast waveform generation capabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  初始化采样器。对于似然值函数，你可以使用AnalysisContainer.eryn_likelihood_function 现在，我们不使用淬火。这个总方案由于似然值估计\n",
    "时间的原因并不是很有效率。所以，我们仅仅把它作为一个例子。你可以在之后长时间运行它或并行化它，这个基本例子说明了快速波形生成能力的重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 3\n",
    "sampler = EnsembleSampler(\n",
    "    nwalkers,\n",
    "    ndim, \n",
    "    analysis.eryn_likelihood_function,\n",
    "    priors,\n",
    "    args=(t_arr,)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the start state and run the sampler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "生成初始状态并运行采样器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = State(priors.rvs(size=(1, nwalkers, 1)))\n",
    "sampler.run_mcmc(start_state, 100, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can examine the chains and/or Likelihood values if you want, but you will likely have to run it for longer to get any reasonable results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "你可以检查链和似然值，如果你需要，但你将可能更长时间地运行它来得到任何合理的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "What types of things can we do to speed up this calculation? Translate this into the waveform environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "问题\n",
    "为了加速计算，我们可以做什么？把这些体现在波形的变化上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Calculate the evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the evidence for the single-peaked Gaussian distribution using thermodynamic integration from Eryn. Use 10 walkers and 50 temperatures to start. You can play with these numbers later and observe their effect on the measurement. Use the `burn` kwarg when running `run_mcmc`. **Important**: for the `tempering_kwargs` keyword argument for `EnsembleSampler`, you must add to the dictionary: `stop_adaptation=burn`. This will adapt the temperatures during burn in and then hold them fixed while recording samples. \n",
    "\n",
    "Useful documentation:\n",
    "* [thermodynamic_integration_log_evidence](https://mikekatz04.github.io/Eryn/html/user/utils.html#eryn.utils.utility.thermodynamic_integration_log_evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "任务4：计算证据\n",
    "  首先，我们要使用Eryn提供的热力学积分（thermodynamic integration）方法来计算单峰高斯分布的证据（evidence）。为进行计算，我们需要使用\n",
    "10个游走状态（walkers）和50个温度（temperatures）来启动。这些数字是初始设置，可以稍后调整它们并观察对测量结果的影响。在运行run_mcmc时，\n",
    "可以使用burn参数（kwarg）来指定烧入（burn-in）的步数。烧入是在采样过程中的初始阶段，用于使采样链收敛到目标分布。在EnsembleSamp\n",
    "ler的tempering_kwargs关键字参数中，必须添加一个字典项：stop_adaptation=burn。这将在烧入期间自适应调整温度，并在记录样本时将其固定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from eryn.utils.utility import thermodynamic_integration_log_evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the sampler. Run the MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "初始化采样器，运行MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = 10\n",
    "ntemps = 50\n",
    "burn = 2000\n",
    "sampler_pt_2 = EnsembleSampler(nwalkers, 1, log_like_gauss, prior, tempering_kwargs=dict(stop_adaptation=burn, ntemps=ntemps, Tmax=np.inf))\n",
    "\n",
    "start_point = prior.rvs(size=(ntemps, nwalkers, 1))\n",
    "start_state = State(start_point)\n",
    "sampler_pt_2.run_mcmc(start_state, 10000, burn=burn, progress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Compute the average likelihood across all samples and walkers **within** each temperature chain.\n",
    "2) Get the inverse temperatures (`betas`) out of the sampler backend and make sure they are the same over the entire run.\n",
    "3) Calculate the evidence.\n",
    "\n",
    "Useful Documentation:\n",
    "* [thermodynamic_integration_log_evidence](https://mikekatz04.github.io/Eryn/html/user/utils.html#eryn.utils.utility.thermodynamic_integration_log_evidence)\n",
    "* [Backend.get_log_like](https://mikekatz04.github.io/Eryn/html/user/backend.html#eryn.backends.Backend.get_log_like)\n",
    "* [Backend.get_betas](https://mikekatz04.github.io/Eryn/html/user/backend.html#eryn.backends.Backend.get_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  1）计算所有样本以及所有温度链上的游走状态的平均似然值2）从采样器获得转换温度(betas)并确保它们在整个过程中相同3）计算证据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logl_avg = sampler_pt_2.get_log_like().mean(axis=(0, 2))\n",
    "betas = sampler_pt_2.get_betas()[-1]\n",
    "assert np.all(betas == sampler_pt_2.get_betas()[0])\n",
    "logz = thermodynamic_integration_log_evidence(betas, logl_avg)\n",
    "print(logz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform model comparison between a Gaussian and Cauchy pulse using thermodynamic integration of the evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the pulse functions and the Likelhiood. We will assume each pulse has an amplitude and mean parameter. We set the standard deviation to be 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "任务5：模型选取\n",
    "   在高斯脉冲与使用证据的热力学积分的柯西脉冲之间进行比较。\n",
    "    这里有脉冲函数以及似然值。我们将假设所有脉冲有着相同的幅度与参数。我们设定1为标准偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import cauchy\n",
    "def gaussian_pulse(x, a, b):\n",
    "    f_x = a * np.exp(-((x - b) ** 2) / (2 * 1.0 ** 2))\n",
    "    return f_x\n",
    "\n",
    "def cauchy_pulse(x, a, b):\n",
    "    f_x = a * cauchy.pdf(x - b)\n",
    "    return f_x\n",
    "\n",
    "def log_like_fn(params, t, data, sigma, which_template):\n",
    "\n",
    "    pulse_gen = gaussian_pulse if which_template == \"gauss\" else cauchy_pulse\n",
    "    template = pulse_gen(t, *params)\n",
    "\n",
    "    ll = -0.5 * np.sum(((template - data) / sigma) ** 2, axis=-1)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vals = np.linspace(-10.0, 10.0, 1000)\n",
    "sigma = 0.2\n",
    "amp_true = 4.0\n",
    "mean_true = 0.0\n",
    "true_data = gaussian_pulse(t_vals, amp_true, mean_true)\n",
    "data = true_data + np.random.randn(*t_vals.shape) * sigma\n",
    "cauchy_data = cauchy_pulse(t_vals, amp_true * 3, mean_true)\n",
    "plt.plot(t_vals, data, label=\"data\")\n",
    "plt.plot(t_vals, true_data, label=\"gauss\")\n",
    "plt.plot(t_vals, cauchy_data, label=\"cauchy\")\n",
    "plt.legend()\n",
    "# plt.plot(x_vals, np.exp(log_like_fn()))\n",
    "# plt.plot(x_vals, np.exp(log_like_gauss(x_vals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to run separate sampler objects for each model. \n",
    "\n",
    "The priors are identical really for the two models. The amplitude prior should span the injection values. The mean prior should span the domain of time.\n",
    "\n",
    "Initialize the priors for each, the sampler for each, sample a start point for each, and run both samplers with the setup we used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "我们需要分别运行每个模型的采样器。\n",
    "   对于两个模型来说先验概率分布确实是一致的，振幅先验应该涵盖输入值，均值先验应该指定时间范围。\n",
    "初始化所有的先验分布和所有的采样器，并对所有的分布的起点进行采样，然后以我们上面用过的设定来运行采样器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = {}\n",
    "samplers = {}\n",
    "burn = 1000\n",
    "for name in [\"gauss\", \"cauchy\"]: \n",
    "    priors[name] = ProbDistContainer({\n",
    "    0: uniform_dist(0.0, 40.0),\n",
    "    1: uniform_dist(t_vals.min(), t_vals.max())\n",
    "})\n",
    "    samplers[name] = EnsembleSampler(\n",
    "        nwalkers,\n",
    "        2,\n",
    "        log_like_fn,\n",
    "        priors,\n",
    "        branch_names=[name],\n",
    "        tempering_kwargs=dict(stop_adaptation=burn, ntemps=ntemps, Tmax=np.inf),\n",
    "        args=(t_vals, data, sigma, name)\n",
    "    )\n",
    "\n",
    "    start_point = priors[name].rvs(size=(ntemps, nwalkers, 1))\n",
    "    start_state = State({name: start_point})\n",
    "    samplers[name].run_mcmc(start_state, 10000, burn=burn, progress=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the calculation from above for both models. Then find Bayes Factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "重复上面的对每一个模型的计算过程。然后确定贝叶斯因子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logz_out = {}\n",
    "for name in [\"gauss\", \"cauchy\"]: \n",
    "    logls = samplers[name].get_log_like().mean(axis=(0, 2))\n",
    "    betas = samplers[name].get_betas()\n",
    "    assert np.all(betas[-1] == betas[0])\n",
    "    logz, dlogz = thermodynamic_integration_log_evidence(betas[0], logls)\n",
    "    print(name, logz, dlogz)\n",
    "    logz_out[name] = logz\n",
    "\n",
    "print(\"2log(Bayes Factor):\", 2 * (logz_out[\"gauss\"] - logz_out[\"cauchy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "If we change the noise, what effect will this have on our results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "问题\n",
    "若我们改变了噪声，我们的结果会受到什么影响？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "收获与总结\n",
    "  这一章的新概念与方法让我有些眼花缭乱，光是马尔科夫链蒙特卡洛方法和并行淬火方法就让我需要画上好一阵子理解，但好在给的提示足够多，至少不至于一点东西也查不到写不出来。\n",
    "  因此，这一章的内容让我对随机过程在实际问题中的应用有了更加深入的了解，尽管我不是数学专业的，对随机过程的学习也仅限在通信技术中，但是我希望可以更加广泛地理解与应用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
